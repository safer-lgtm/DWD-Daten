---
title: "Projekt"
author: "Safouan"
date: '2022-06-12'
output: html_document
---

```{r}
# Libraries importieren
library(rdwd)
library(lubridate)
library(foreach)
library(sf)
library(tidyr)
library(dplyr)
library(DBI)
library(RPostgres)
library(ggplot2)
library(viridisLite)
library(viridis)

# Funktion, um DWD-Daten herunterzuladen
herunterladen <- function(auflösung, variable, probezeit){
    links <- selectDWD(res=auflösung, var=variable, per=probezeit)
    data <- foreach(i=1:length(links), .combine=rbind) %do% {
        file <- dataDWD(links[i], read=FALSE, dir='DWDdata')
        clim <- readDWD(file, varnames=TRUE)
    }    
    return(data)
}

# Überschreiben der %+%-Operator, um eine bessere Syntax für die String-Verkettung zu erhalten
'%+%' <- function(x,y) paste(x, y, sep = "")

# Funktion, um DWD-Daten in TimeScale Datenbank zu speichern
saveToTimeScaleDB <- function(connection, data, tbl_name, partitioned_on='MESS_DATUM') {
    # Erstellen einer reguläre PostgreSQL-Tabelle
    dbWriteTable(con, tbl_name, data, overwrite=T)
    
    # Konvertieren Sie die reguläre Tabelle in eine Hypertabelle, die nach der Spalte MESS_DATUM partitioniert ist und deren Intervall (chunck interval) 1 Monat beträgt
    query <- "SELECT create_hypertable(" %+% "'" %+% tbl_name %+% "'" %+% ',' %+% "'" %+% partitioned_on %+% "'" %+% ',' %+% "migrate_data => true" %+% ',' %+% "chunk_time_interval => INTERVAL '1 month')"
    rs <- dbSendQuery(con, query)
    dbClearResult(rs)
}

# Funktion, um die historische Daten einmalig sowie die neueste Daten 
durchführen <- function(recent_data, tbl_recent='recent_temperature', historical_data, tbl_historical='temperatur'){
    # Die Speicheung der neuesten Daten in TimeScaleDB  
    saveToTimeScaleDB(con, recent_data, tbl_recent)
    
    # Speicheung der historischen Daten in TimeScaleDB
    saveToTimeScaleDB(con, historical_data, tbl_historical)
    
    # Merge data
    query <- "INSERT INTO " %+%  tbl_historical  %+% " SELECT * FROM "  %+% tbl_recent
    rs <- dbSendQuery(con, query)
    dbClearResult(rs)
}

# Verbindung zu einer bestimmten Postgres-Datenbank
con <- dbConnect(Postgres(), dbname = 'postgres', 
                 host = 'localhost',
                 port = 5432,
                 user = 'postgres',
                 password = 'PostgreSQL@22')


recent_weather <- herunterladen("daily", "weather_phenomena", "recent")
historical_weather <- herunterladen("daily", "weather_phenomena", "recent")
data(geoIndex)
# Die Speicheung der Geografiedaten in TimeScaleDB  
dbWriteTable(con, "geometry", geoIndex, overwrite=T)

# Datenspeicherung in TimeScaleDB
durchführen(recent_weather, 'recent_weather', historical_weather, 'weather')
#query <- read_file("script.sql")
param = 'GEWITTER.Gewitter'
average <- dbGetQuery(con, 
    'SELECT g."state" "Bundesland", 
    avg(w.' %+% '"' %+% param %+% '"' %+% ') "durchschnitt_weather" 
    FROM weather w
    INNER JOIN geometry g  ON w."STATIONS_ID" = g."id" 
    GROUP BY "state"')

# Postgres-Verbindung schließen
dbDisconnect(con)

# Laden der Shapefile von Deutschland per Bundesland
germany_shp <- read_sf('DEU_adm/DEU_adm1.shp')

# Fortify and Join with Temperatures:
germany_shp.df <- merge(fortify(germany_shp), as.data.frame(temp), by.x="NAME_1", by.y="Bundesland")

germany_shp.df$avg_weather

ggplot(germany_shp.df) +
    geom_sf(aes(fill=avg_weather)) +
    scale_fill_viridis()

```